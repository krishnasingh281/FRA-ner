{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda6c302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reconstructed Text (First 1000 Chars) ---\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Cleaned Text (First 800 Chars) ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "from statistics import median\n",
    "\n",
    "# Load OCR JSON\n",
    "with open('../data/ocr_jsons/sample.json', 'r', encoding='utf-8') as f:\n",
    "    ocr = json.load(f)\n",
    "\n",
    "# --- START: MODIFIED SECTION ---\n",
    "# This part is fixed to handle a common JSON structure (e.g., from Google Vision API)\n",
    "\n",
    "# The 'textAnnotations' key is common. The first element is the full text, the rest are individual words.\n",
    "word_annotations = ocr.get('textAnnotations', [])\n",
    "\n",
    "words = []\n",
    "if word_annotations:\n",
    "    # We skip the first annotation [0] as it's the entire text block.\n",
    "    for annotation in word_annotations[1:]:\n",
    "        # Adapt the data structure to what the rest of the script expects\n",
    "        transformed_word = {\n",
    "            'text': annotation.get('description', ''),\n",
    "            'bbox': [(v.get('x', 0), v.get('y', 0)) for v in annotation.get('boundingPoly', {}).get('vertices', [])]\n",
    "        }\n",
    "        words.append(transformed_word)\n",
    "# --- END: MODIFIED SECTION ---\n",
    "\n",
    "\n",
    "# Get centroid of bbox for sorting (This part remains the same)\n",
    "for w in words:\n",
    "    if w['bbox']:\n",
    "        xs = [p[0] for p in w['bbox']]\n",
    "        ys = [p[1] for p in w['bbox']]\n",
    "        w['cx'] = sum(xs) / len(xs)\n",
    "        w['cy'] = sum(ys) / len(ys)\n",
    "    else:\n",
    "        w['cx'] = 0\n",
    "        w['cy'] = 0\n",
    "\n",
    "# Group into lines by Y coordinate\n",
    "def group_words_into_lines(words, y_tol=10):\n",
    "    # Sort words by y then x\n",
    "    words_sorted = sorted(words, key=lambda w: (w['cy'], w['cx']))\n",
    "    lines = []\n",
    "    for w in words_sorted:\n",
    "        placed = False\n",
    "        for line in lines:\n",
    "            # Check if the word belongs to an existing line\n",
    "            if abs(line['median_y'] - w['cy']) <= y_tol:\n",
    "                line['words'].append(w)\n",
    "                # Recalculate the median Y for the line\n",
    "                line['median_y'] = median([wd['cy'] for wd in line['words']])\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            # Create a new line for this word\n",
    "            lines.append({'median_y': w['cy'], 'words': [w]})\n",
    "    \n",
    "    # Convert word groups to text strings and get line bounds\n",
    "    for line in lines:\n",
    "        line['words'].sort(key=lambda x: x['cx']) # Sort words in the line by X\n",
    "        line['text'] = ' '.join([wd['text'] for wd in line['words']])\n",
    "        line['x_min'] = min([p[0] for wd in line['words'] for p in wd['bbox']])\n",
    "        line['x_max'] = max([p[0] for wd in line['words'] for p in wd['bbox']])\n",
    "    \n",
    "    # Sort lines by their Y position before returning\n",
    "    return sorted(lines, key=lambda l: l['median_y'])\n",
    "\n",
    "lines = group_words_into_lines(words, y_tol=12)\n",
    "text_reconstructed = '\\n'.join([ln['text'] for ln in lines])\n",
    "print(\"--- Reconstructed Text (First 1000 Chars) ---\")\n",
    "print(text_reconstructed[:1000])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Simple fixes\n",
    "COMMON_FIXES = [\n",
    "    (r'\\s+', ' '),\n",
    "    (r\"0f\", \"of\"),\n",
    "    (r\"Narne\", \"Name\"),\n",
    "]\n",
    "\n",
    "def apply_common_fixes(text):\n",
    "    for pat, rep in COMMON_FIXES:\n",
    "        text = re.sub(pat, rep, text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_text = apply_common_fixes(text_reconstructed)\n",
    "print(\"--- Cleaned Text (First 800 Chars) ---\")\n",
    "print(clean_text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44467a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
